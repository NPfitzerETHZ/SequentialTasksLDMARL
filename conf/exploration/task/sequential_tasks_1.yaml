
name: SAMPLING                          # maps to VmasTask.SAMPLING
scenario_class: scenarios.exploration.multi_agent_sequential.MyLanguageScenario

params:
  # === Map & Scenario Layout ===
  x_semidim: 1.0
  y_semidim: 1.0
  covering_range: 0.15
  agent_radius: 0.03
  n_obstacles: 0

  # === Agent/Target Counts & Behavior ===
  n_agents: 3
  agents_per_target: 1
  n_targets_per_class: 1
  n_target_classes: 1
  n_targets: 1
  done_at_termination: false

  # === Rewards ===
  reward_scale_factor: 0.1
  shared_target_reward: true
  shared_final_reward: true
  agent_collision_penalty: 0.0
  obstacle_collision_penalty: -0.5
  covering_rew_coeff: 7.0
  false_covering_penalty_coeff: -0.25
  time_penalty: -0.05
  terminal_rew_coeff: 15.0
  exponential_search_rew_coeff: 1.5
  termination_penalty_coeff: -0.0

  # === Exploration Rewards ===
  use_expo_search_rew: true
  grid_visit_threshold: 2
  exploration_rew_coeff: -0.05
  new_cell_rew_coeff: 0.00
  heading_exploration_rew_coeff: 30
  memory_grid_radius: 3
  gaussian_heading_sigma_coef: 0.1

  # === Defend Rewards ===
  defend_behaviour_factor: 1.0
  defend_dist_shaping_factor: 1.0
  desired_distance:             # <-- Added
    3: 0.4                      # DEFEND_WIDE = 3
    4: 0.1                      # DEFEND_TIGHT = 4
  stillness_speed_thresh: 0.05 # <-- Added
  stillness_penalty: -0.25     # <-- Added
  target_proximity_reward: 0.5 # <-- Added

  # === Navigation Rewards ===
  nav_pos_shaping_factor: 1.0
  nav_final_reward: 10.0
  nav_shared_rew: false        # <-- Added

  # === Lidar & Sensing ===
  use_lidar: false
  n_lidar_rays_entities: 8
  n_lidar_rays_agents: 12
  max_agent_observation_radius: 0.3
  prediction_horizon_steps: 1

  # === Agent Communication & GNNs ===
  use_gnn: ${exploration.model.model_shared.use_gnn}
  use_conv_2d: ${exploration.model.model_shared.use_conv_2d}
  comm_dim: 0
  comms_radius: ${exploration.model.model_shared.comms_radius}

  # === Observation Settings ===
  observe_grid: true
  observe_targets: true
  observe_agents: false
  observe_pos_history: false
  observe_vel_history: false
  use_grid_data: true
  use_class_data: false
  use_max_targets_data: false
  use_confidence_data: false
  use_team_level_target_count: false

  # === Grid Settings ===
  num_grid_cells: 400
  mini_grid_radius: 1

  # === Movement & Dynamics ===
  use_velocity_controller: false
  use_kinematic_model: false
  agent_weight: 1.0
  agent_v_range: 0.25
  agent_a_range: 1.0
  min_collision_distance: 0.05
  linear_friction: 0.1

  # === Histories ===
  history_length: 0

  # === Language & LLM Goals ===
  embedding_size: 1024
  use_embedding_ratio: 1.0
  llm_activate: true

  # === External Inputs ===
  data_json_path: data/dataset_full.json
  decoder_model_path: decoders/llm0_decoder_model_grid_scale.pth
  sequence_model_path: sequence_models/event_rnn_best_gru-in64-bs128.pth
  use_decoder: true
  use_sequence_model: true
  event_dim: 3
  state_dim: 6

  # === Visuals ===
  viewer_zoom: 1

  # === Additional Scenario ===
  max_steps: 250
